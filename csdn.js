{"response_index":1,"req_time_stamp":213123,"abstract":"CUDAC简介CPU上的HelloWorldGPU上的HelloWorld__global__修饰符：向kernal()中传递参数cudaMalloc()函数：cudaFree()函数：cudaMemcpy()函数：查询设备信息cudaGetDeviceCount()函数：结构体cudaDevicePropcudaGetDeviceProperties()函数：设备属性的使用：选择一个符合条...作者：wolfcsharp242019-07-24","text":"CUDAC简介CPU上的HelloWorldGPU上的HelloWorld__global__修饰符：向kernal()中传递参数cudaMalloc()函数：cudaFree()函数：cudaMemcpy()函数：查询设备信息cudaGetDeviceCount()函数：结构体cudaDevicePropcudaGetDeviceProperties()函数：设备属性的使用：选择一个符合条件约束的设备cudaGetDevice()函数：cudaChooseDevice()函数：cudaSetDevice()函数：本章小结CPU上的HelloWorld/*//代码3.2.1:在CPU上运行C程序//时间：2019.07.20#include&lt;iostream&gt;intmain(void){printf(\"Hello,world!\\n\");system(\"pause\");return0;}GPU上的HelloWorld我们将CPU以及系统的内存称为Host，而将GPU及其内存称为Device，在GPUDevice上执行的函数通常称为Kernal。/*//代码3.2.2:在GPU上运行CUDAC程序，在CPU上运行C程序//时间：2019.07.20*/#include\"cuda_runtime.h\"#include\"device_launch_parameters.h\"#include&lt;iostream&gt;__global__voidkernal(){}intmain(void){kernal&lt;&lt;&lt;1,1&gt;&gt;&gt;();printf(\"Hello,world!\\n\");system(\"pause\");return0;}*/与CPU的HelloWorld相比，GPU的HelloWorld多了两个值得注意的地方：(1)一个空的函数kernal(),并且带有修饰符__global__(2)对这个空函数的调用，并且带有修饰字符&lt;&lt;&lt;1,1&gt;&gt;&gt;__global__修饰符：CUDAC为标准C增加了__global__修饰符。这个修饰符将告诉编译器，该函数应该编译为在设备上执行而不是编译为主机执行,__global__修饰符正是Host调用Device的接口在这个简单是示例中，函数kernal()将被交给编译GPU设备代码的编译器进行编译，而main()函数将被交给CPU主机编译器进行编译。至于修饰字符&lt;&lt;&lt;1,1&gt;&gt;&gt;我们留在以后再解释，现在只要知道这个修饰字符跟怎样组织GPU的并行性有关即可。向kernal()中传递参数/*//代码3.2.3传递参数//时间：2019.07.20*/#include\"cuda_runtime.h\"#include\"device_launch_parameters.h\"#include&lt;iostream&gt;__global__voidadd(inta,intb,int*c){*c=a+b;}intmain(void){intc;int*dev_c;//第一个参数是一个指针，指向用于保存新分配内存地址的变量//第二个参数是分配内存的大小//返回类型为void*,这与C语言中malloc()返回分配内存的指针存在不同cudaMalloc((void**)&amp;dev_c,sizeof(int));//需要注意的是：//可以将cudaMalloc()分配的指针传递给在设备上执行的函数//可以在设备代码中使用cudaMalloc()分配的指针进行内存读写操作//可以将cudaMalloc()分配的指针传递给在主机上执行的函数//不能在主机代码中使用cudaMalloc()分配的指针进行内存读写操作add&lt;&lt;&lt;1,1&gt;&gt;&gt;(2,4,dev_c);//cudaMemcpy，第一个参数是主机指针，第二个参数是设备指针，第三个参数指明内存copy的大小//cudaMemcpyDeviceToHost，指明运行时源指针是一个设备指针，而目标指针是一个主机指针cudaMemcpy(&amp;c,dev_c,sizeof(int),cudaMemcpyDeviceToHost);cudaFree(dev_c);printf(\"2+4=%d\\n\",c);system(\"pause\");return0;}这里新增了多行代码，在这些代码中包含两个概念：(1)可以像调用C函数那样将参数传递给核函数(2)当设备执行任何有用的操作时，都需要分配内存cudaMalloc()函数：在设备存储空间中为变量分配内存：cudaMalloc()函数除了分配内存的指针不是作为函数的返回值外，其他的行为与malloc()是相同的，并且返回类型为void*第一个参数是一个指针，指向用于保存新分配内存地址的变量，第二个参数是分配内存的大小。注意，程序员一定不能在主机代码中对cudaMalloc()返回的指针进行解引用。综上,将Device指针的使用限制总结如下：(1)可以将cudaMalloc()分配的指针传递给在设备上执行的函数(2)可以在Device代码中使用cudaMalloc()分配的指针进行内存读写操作(3)可以将cudaMalloc()分配的的指针传递给在主机上执行的函数(4)不能在主机代码中使用cudaMalloc()分配的指针进行内存读写操作主机指针只能访问主机代码中的内存，设备指针只能访问设备代码中的内存。cudaFree()函数：类似于标准C中的free()函数，cudaFree用于释放在GPU上分配的空间。cudaMemcpy()函数：在主机代码中可以通过调用cudaMemcpy()函数来访问设备上的内存。这个函数调用的行为类似于标准C中的memcpy(),只不过多了一个参数来指定设备内存指针究竟是源指针还是目标指针。函数参数说明，第一个参数是目标指针，第二个参数是源指针，第三个参数指明内存copy的大小，第四个参数指明内存copy的方向。比如，目标指针是device，源指针是device，第四个参数设置为cudaMemcpyDeviceToHost，这个参数将指明运行时源指针是一个设备指针，而目标指针是一个主机指针。查询设备信息/*//代码3.3查询设备//时间：2019.07.20*/#include\"cuda_runtime.h\"#include\"device_launch_parameters.h\"#include&lt;iostream&gt;intmain(void){cudaDevicePropprop;intcount;cudaGetDeviceCount(&amp;count);for(inti=0;i&lt;count;i++){cudaGetDeviceProperties(&amp;prop,i);printf(\"---GeneralInformationfordevice%d---\\n\",i);printf(\"Name:%s\\n\",prop.name);printf(\"Computecapability:%d.%d\\n\",prop.major,prop.minor);printf(\"Clockrate:%d\\n\",prop.clockRate);printf(\"Devicecopyoverlap:\");if(prop.deviceOverlap)printf(\"Enabled\\n\");elseprintf(\"Disabled\\n\");printf(\"Kernalexecitiontimeout:\");if(prop.kernelExecTimeoutEnabled)printf(\"Enabled\\n\");elseprintf(\"Disabled\\n\");printf(\"---MemoryInformationfordevice%d---\\n\",i);printf(\"TotalglobalMem:%ld\\n\",prop.totalGlobalMem);printf(\"TotalconstantMem:%ld\\n\",prop.totalConstMem);printf(\"Maxmempitch:%ld\\n\",prop.memPitch);printf(\"TextureAlignment:%ld\\n\",prop.textureAlignment);printf(\"---MPInformationfordevice%d---\\n\",i);printf(\"Multiprocessorcopunt:%d\\n\",prop.multiProcessorCount);printf(\"Sharedmempermp:%ld\\n\",prop.sharedMemPerBlock);printf(\"Registerspermp:%d\\n\",prop.regsPerBlock);printf(\"Threadsinwarp:%d\\n\",prop.warpSize);printf(\"Maxthreaddimensions:(%d,%d,%d)\\n\",prop.maxThreadsDim[0],prop.maxThreadsDim[1],prop.maxThreadsDim[2]);printf(\"Maxgriddimensions:(%d,%d,%d)\\n\",prop.maxGridSize[0],prop.maxGridSize[1],prop.maxGridSize[2]);printf(\"\\n\");}system(\"pause\");}cudaGetDeviceCount()函数：如果硬件设备中包含有多个CUDA设备，可以通过cudaGetDeviceCount()函数获得CUDA设备的数量。结构体cudaDeviceProp用于存储设备的相关属性/***CUDAdeviceproperties*/struct__device_builtin__cudaDeviceProp{charname[256];/**&lt;ASCIIstringidentifyingdevice*/size_ttotalGlobalMem;/**&lt;Globalmemoryavailableondeviceinbytes*/size_tsharedMemPerBlock;/**&lt;Sharedmemoryavailableperblockinbytes*/intregsPerBlock;/**&lt;32-bitregistersavailableperblock*/intwarpSize;/**&lt;Warpsizeinthreads*/size_tmemPitch;/**&lt;Maximumpitchinbytesallowedbymemorycopies*/intmaxThreadsPerBlock;/**&lt;Maximumnumberofthreadsperblock*/intmaxThreadsDim[3];/**&lt;Maximumsizeofeachdimensionofablock*/intmaxGridSize[3];/**&lt;Maximumsizeofeachdimensionofagrid*/intclockRate;/**&lt;Clockfrequencyinkilohertz*/size_ttotalConstMem;/**&lt;Constantmemoryavailableondeviceinbytes*/intmajor;/**&lt;Majorcomputecapability*/intminor;/**&lt;Minorcomputecapability*/size_ttextureAlignment;/**&lt;Alignmentrequirementfortextures*/size_ttexturePitchAlignment;/**&lt;Pitchalignmentrequirementfortexturereferencesboundtopitchedmemory*/intdeviceOverlap;/**&lt;Devicecanconcurrentlycopymemoryandexecuteakernel.Deprecated.UseinsteadasyncEngineCount.*/intmultiProcessorCount;/**&lt;Numberofmultiprocessorsondevice*/intkernelExecTimeoutEnabled;/**&lt;Specifiedwhetherthereisaruntimelimitonkernels*/intintegrated;/**&lt;Deviceisintegratedasopposedtodiscrete*/intcanMapHostMemory;/**&lt;DevicecanmaphostmemorywithcudaHostAlloc/cudaHostGetDevicePointer*/intcomputeMode;/**&lt;Computemode(See::cudaComputeMode)*/intmaxTexture1D;/**&lt;Maximum1Dtexturesize*/intmaxTexture1DMipmap;/**&lt;Maximum1Dmipmappedtexturesize*/intmaxTexture1DLinear;/**&lt;Maximumsizefor1Dtexturesboundtolinearmemory*/intmaxTexture2D[2];/**&lt;Maximum2Dtexturedimensions*/intmaxTexture2DMipmap[2];/**&lt;Maximum2Dmipmappedtexturedimensions*/intmaxTexture2DLinear[3];/**&lt;Maximumdimensions(width,height,pitch)for2Dtexturesboundtopitchedmemory*/intmaxTexture2DGather[2];/**&lt;Maximum2Dtexturedimensionsiftexturegatheroperationshavetobeperformed*/intmaxTexture3D[3];/**&lt;Maximum3Dtexturedimensions*/intmaxTexture3DAlt[3];/**&lt;Maximumalternate3Dtexturedimensions*/intmaxTextureCubemap;/**&lt;MaximumCubemaptexturedimensions*/intmaxTexture1DLayered[2];/**&lt;Maximum1Dlayeredtexturedimensions*/intmaxTexture2DLayered[3];/**&lt;Maximum2Dlayeredtexturedimensions*/intmaxTextureCubemapLayered[2];/**&lt;MaximumCubemaplayeredtexturedimensions*/intmaxSurface1D;/**&lt;Maximum1Dsurfacesize*/intmaxSurface2D[2];/**&lt;Maximum2Dsurfacedimensions*/intmaxSurface3D[3];/**&lt;Maximum3Dsurfacedimensions*/intmaxSurface1DLayered[2];/**&lt;Maximum1Dlayeredsurfacedimensions*/intmaxSurface2DLayered[3];/**&lt;Maximum2Dlayeredsurfacedimensions*/intmaxSurfaceCubemap;/**&lt;MaximumCubemapsurfacedimensions*/intmaxSurfaceCubemapLayered[2];/**&lt;MaximumCubemaplayeredsurfacedimensions*/size_tsurfaceAlignment;/**&lt;Alignmentrequirementsforsurfaces*/intconcurrentKernels;/**&lt;Devicecanpossiblyexecutemultiplekernelsconcurrently*/intECCEnabled;/**&lt;DevicehasECCsupportenabled*/intpciBusID;/**&lt;PCIbusIDofthedevice*/intpciDeviceID;/**&lt;PCIdeviceIDofthedevice*/intpciDomainID;/**&lt;PCIdomainIDofthedevice*/inttccDriver;/**&lt;1ifdeviceisaTesladeviceusingTCCdriver,0otherwise*/intasyncEngineCount;/**&lt;Numberofasynchronousengines*/intunifiedAddressing;/**&lt;Devicesharesaunifiedaddressspacewiththehost*/intmemoryClockRate;/**&lt;Peakmemoryclockfrequencyinkilohertz*/intmemoryBusWidth;/**&lt;Globalmemorybuswidthinbits*/intl2CacheSize;/**&lt;SizeofL2cacheinbytes*/intmaxThreadsPerMultiProcessor;/**&lt;Maximumresidentthreadspermultiprocessor*/intstreamPrioritiesSupported;/**&lt;Devicesupportsstreampriorities*/intglobalL1CacheSupported;/**&lt;DevicesupportscachingglobalsinL1*/intlocalL1CacheSupported;/**&lt;DevicesupportscachinglocalsinL1*/size_tsharedMemPerMultiprocessor;/**&lt;Sharedmemoryavailablepermultiprocessorinbytes*/intregsPerMultiprocessor;/**&lt;32-bitregistersavailablepermultiprocessor*/intmanagedMemory;/**&lt;Devicesupportsallocatingmanagedmemoryonthissystem*/intisMultiGpuBoard;/**&lt;Deviceisonamulti-GPUboard*/intmultiGpuBoardGroupID;/**&lt;Uniqueidentifierforagroupofdevicesonthesamemulti-GPUboard*/inthostNativeAtomicSupported;/**&lt;Linkbetweenthedeviceandthehostsupportsnativeatomicoperations*/intsingleToDoublePrecisionPerfRatio;/**&lt;Ratioofsingleprecisionperformance(infloating-pointoperationspersecond)todoubleprecisionperformance*/intpageableMemoryAccess;/**&lt;DevicesupportscoherentlyaccessingpageablememorywithoutcallingcudaHostRegisteronit*/intconcurrentManagedAccess;/**&lt;DevicecancoherentlyaccessmanagedmemoryconcurrentlywiththeCPU*/intcomputePreemptionSupported;/**&lt;DevicesupportsComputePreemption*/intcanUseHostPointerForRegisteredMem;/**&lt;DevicecanaccesshostregisteredmemoryatthesamevirtualaddressastheCPU*/intcooperativeLaunch;/**&lt;Devicesupportslaunchingcooperativekernelsvia::cudaLaunchCooperativeKernel*/intcooperativeMultiDeviceLaunch;/**&lt;Devicecanparticipateincooperativekernelslaunchedvia::cudaLaunchCooperativeKernelMultiDevice*/size_tsharedMemPerBlockOptin;/**&lt;Perdevicemaximumsharedmemoryperblockusablebyspecialoptin*/intpageableMemoryAccessUsesHostPageTables;/**&lt;Deviceaccessespageablememoryviathehost'spagetables*/intdirectManagedMemAccessFromHost;/**&lt;Hostcandirectlyaccessmanagedmemoryonthedevicewithoutmigration.*/};cudaGetDeviceProperties()函数：用于获得指定编号设备的属性信息，第一个参数是cudaDeviceProp类型的指针，第二个参数指定GPU设备编号，如果有N个GPU设备，设备编号从0开始一直到N-1。cudaDevicePropprop;cudaGetDeviceProperties(&amp;prop,0);//获得第0个GPU设备的属性信息设备属性的使用：选择一个符合条件约束的设备/*//代码3.4设备属性的使用:选择一个符合条件约束的设备//时间：2019.07.20*/#include\"cuda_runtime.h\"#include\"device_launch_parameters.h\"#include&lt;iostream&gt;intmain(){cudaDevicePropprop;intdev;//获得当前的GPU设备cudaGetDevice(&amp;dev);printf(\"IDofcurrentCUDAdevice:%d\\n\",dev);//筛选符合要求的设备memset(&amp;prop,0,sizeof(cudaDeviceProp));prop.major=1;prop.minor=3;cudaChooseDevice(&amp;dev,&amp;prop);printf(\"IDofCUDAdeviceclosettoreversion1.3:%d\\n\",dev);//设置为筛选出来的GPU设备cudaSetDevice(dev);system(\"pause\");}假设我们的代码对显卡的版本也有所要求，只有在版本为1.3及以上的计算功能集版本显卡上才能够运行，为了让我们的代码具有更好的鲁棒性，需要筛选出符合要求的GPU来执行代码。根据cudaGetDeviceCount()和cudaGetDeviceProperties()中返回的结果，我们可以对每个设备进行迭代，并且查找主版本号大于1，或者主版本号为1且次版本号大于等于3的设备。其实，CUDA运行时提供了一种自动方式来执行这个迭代操作：首先，找出我们希望设备拥有的属性并将这些属性填充到一个cudaDeviceProp结构中在填充完cudaDeviceProp之后，将其传递给cudaChooseDevice(),这样CUDA运行时将查找是否存在某个设备满足这些条件。cudaChooseDevice()函数将返回一个设备ID，这个ID就是符合我们筛选要求的GPU，然后我们可以将这个ID传递给cudaSetDevice(),之后所有的设备操作都将在这个设备上执行。cudaGetDevice()函数：获得当前运行使用的GPUID。输入参数为用于盛放设备ID的地址，cudaGetDevice()函数将用当前设备ID填充这个指针指向的内存。cudaChooseDevice()函数：根据cudaDeviceProp设定的筛选条件进行设备筛选。第一个参数为用于盛放筛选结果的地址，第二个参数为cudaDeviceProp类型筛选条件的内存地址。cudaSetDevice()函数：设置使用指定的GPU。输入参数为指定GPU的ID。本章小结1.__global__修饰符2.cudaMalloc()函数3.cudaFree()函数4.cudaMemcpy()函数5.cudaGetDeviceCount()函数6.结构体cudaDeviceProp7.cudaGetDeviceProperties()函数8.cudaGetDevice()函数9.cudaChooseDevice()函数10.cudaSetDevice()函数","chapter_id":2,"source_id":"1","title":"CUDA by example Chapter3 CUDA C简介_wolfcsharp的博客-CSDN博客"}